@article{Gerst2020,
   abstract = {Visually communicating temperature and precipitation climate outlook graphics is challenging because it requires the viewer to be familiar with probabilities as well as to have the visual literacy to interpret geospatial forecast uncertainty. In addition, the visualization scientific literature has open questions on which visual design choices are the most effective at expressing the multidimensionality of uncertain forecasts, leaving designers with a lack of concrete guidance. Using a two-phase experimental setup, this study shows how recently developed visualization diagnostic guidelines can be used to iteratively diagnose, redesign, and test the understandability the U.S. National Oceanic and Atmospheric Administration (NOAA) Climate Prediction Center (CPC) climate outlooks. In the first phase, visualization diagnostic guidelines were used in conjunction with interviews and focus groups to identify understandability challenges of existing visual conventions in temperature and precipitation outlooks. Next, in a randomized control versus experimental treatment setup, several graphic modifications were produced and tested via an online survey of end users and the general public. Results show that, overall, end users exhibit a better understanding of outlooks, but some types of probabilistic color mapping are misunderstood by both end users and the general public, which was predicted by the diagnostic guidelines. Modifications lead to significant gains in end-user and general public understanding of climate outlooks, providing additional evidence for the utility of using control versus treatment testing informed by visualization diagnostics.},
   author = {Michael D Gerst and Melissa A Kenney and Allison E Baer and Amanda Speciale and J Felix Wolfinger and Jon Gottschalck and Scott Handel and Matthew Rosencrans and David Dewitt},
   doi = {10.1175/WCAS-D-18-0094.s1},
   issue = {1},
   journal = {Weather, Climate, and Society},
   pages = {117-133},
   title = {Using Visualization Science to Improve Expert and Public Understanding of Probabilistic Temperature and Precipitation Outlooks},
   volume = {12},
   url = {https://doi.org/10.1175/WCAS-D-18-0094.s1.},
   year = {2020},
}
@report{Townsend2014,
   author = {H M Townsend and C Harvey and K Y Aydin and R Gamble and A Grüss and P S Levin and J S Link and K E Osgood and J Polovina and M J Schirripa and B Wells},
   title = {Report of the 3rd National Ecosystem Modeling Workshop (NEMoW 3): Mingling Models for Marine Resource Management-Multiple Model Inference. U.S. Dept. of Commerce, NOAA Tech. Memo. NMFS-F/SPO-149, 93 p},
   url = {https://spo.nmfs.noaa.gov/sites/default/files/TM149.pdf},
   year = {2014},
}
@article{Reed2020,
   abstract = {There have been multiple efforts in recent years to simplify visual weather forecast products, with the goal of more efficient risk communication for the general public. Many meteorological forecast products, such as the cone of uncertainty, storm surge graphics, warning polygons, and Storm Prediction Center (SPC) convective outlooks, have created varying levels of public confusion resulting in revisions, modifications, and improvements. However, the perception and comprehension of private weather graphics produced by television stations has been largely overlooked in peer-reviewed research. The goal of this study is to explore how the extended forecast graphic, more commonly known as the 7, 10 day, etc., is utilized by broadcasters and understood by the public. Data were gathered from surveys with the general public and also from broadcast meteorologists. Results suggest this graphic is a source of confusion and highlights a disconnect between the meteorologists producing the graphic and the content prioritized by their audiences. Specifically, timing and intensity of any precipitation or adverse weather events are the two most important variables to consider from the viewpoint of the public. These variables are generally absent from the extended forecast graphic, thus forcing the public to draw their own conclusions, which may differ from what the meteorologist intends to convey. Other results suggest the placement of forecast high and low temperatures, use of probability of precipitation, icon inconsistency, and length of time the graphic is shown also contribute to public confusion and misunderstanding.},
   author = {Jacob R. Reed and Jason C. Senkbeil},
   doi = {10.1175/BAMS-D-19-0078.1},
   issn = {00030007},
   issue = {2},
   journal = {Bulletin of the American Meteorological Society},
   pages = {E221-E236},
   publisher = {American Meteorological Society},
   title = {Perception and comprehension of the extended forecast graphic: A survey of broadcast meteorologists and the public},
   volume = {101},
   year = {2020},
}
@article{Morss2008,
   abstract = {Weather forecasts are inherently uncertain, and meteorologists have information about weather forecast uncertainty that is not readily available to most forecast users. Yet effectively communicating forecast uncertainty to nonmeteorologists remains challenging. Improving forecast uncertainty communication requires research-based knowledge that can inform decisions on what uncertainty information to communicate, when, and how to do so. To help build such knowledge, this article explores the public's perspectives on everyday weather forecast uncertainty and uncertainty information using results from a nationwide survey. By contributing to the fundamental understanding of laypeople's views on forecast uncertainty, the findings can inform both uncertainty communication and related research. The article uses empirical data from a nationwide survey of the U.S. public to investigate beliefs commonly held among meteorologists and to explore new topics. The results show that when given a deterministic temperature forecast, most respondents expected the temperature to fall within a range around the predicted value. In other words, most people inferred uncertainty into the deterministic forecast. People's preferences for deterministic versus nondeterministic forecasts were examined in two situations; in both, a significant majority of respondents liked weather forecasts that expressed uncertainty, and many preferred such forecasts to single-valued forecasts. The article also discusses people's confidence in different types of forecasts, their interpretations of the probability of precipitation forecasts, and their preferences for how forecast uncertainty is conveyed. Further empirical research is needed to study the article's findings in other contexts and to continue exploring perception, interpretation, communication, and use of weather forecast uncertainty. © 2008 American Meteorological Society.},
   author = {Rebecca E. Morss and Julie L. Demuth and Jeffrey K. Lazo},
   doi = {10.1175/2008WAF2007088.1},
   issn = {08828156},
   issue = {5},
   journal = {Weather and Forecasting},
   pages = {974-991},
   title = {Communicating uncertainty in weather forecasts: A survey of the U.S. public},
   volume = {23},
   year = {2008},
}
@article{Kotsuki2019,
   abstract = {Evaluating impacts of observations on the skill of numerical weather prediction (NWP) is important. The Ensemble Forecast Sensitivity to Observation (EFSO) provides an efficient approach to diagnosing observation impacts, quantifying how much each observation improves or degrades a subsequent forecast with a given verification reference. This study investigates the sensitivity of EFSO impact estimates to the choice of the verification reference, using a global NWP system consisting of the Non-hydrostatic Icosahedral Atmospheric Model (NICAM) and the Local Ensemble Transform Kalman Filter (LETKF). The EFSO evaluates observation impacts with the moist total energy norm and with recently proposed observation-based verification metrics. The results show that each type of observation mainly contributes to the improvement of forecast departures of the observed variable maybe due to the limitation of localization in the EFSO. The EFSO overestimates the fraction of beneficial observations when verified with subsequent analyses, especially for shorter lead times such as 6 h. We may avoid this overestimation to some extent by verifying with observations, analyses from other data assimilation (DA) systems, or analyses of an independent run with the same DA system. In addition, this study demonstrates two important issues possibly leading to overestimating observation impacts. First, observation impacts would be overestimated if we apply relaxation-to-prior methods to the initial conditions of the ensemble forecasts in the EFSO; therefore, the ensemble forecasts in the EFSO should be independent of the ensemble forecasts in the DA cycle. Second, deterministic baseline forecasts of the EFSO, which represent the forecast without DA, should be initialized by the ensemble mean of the first guess at the analysis time, not by the previous analysis.},
   author = {Shunji Kotsuki and Kenta Kurosawa and Takemasa Miyoshi},
   doi = {10.1002/qj.3534},
   issn = {1477870X},
   issue = {722},
   journal = {Quarterly Journal of the Royal Meteorological Society},
   keywords = {NICAM-LETKF,data assimilation,ensemble Kalman filter,ensemble forecast sensitivity to observations,verification reference},
   month = {7},
   pages = {1897-1914},
   publisher = {John Wiley and Sons Ltd},
   title = {On the properties of ensemble forecast sensitivity to observations},
   volume = {145},
   year = {2019},
}
